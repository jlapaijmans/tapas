# This is supposed to follow the idea of literate programming.
# In case anyone executes this as a script
set -ueC

#' Reads from three origins are generated and their read names will contain
#' their origin genome and their true mapping

#' Define variables for later use
#' ==============================
#'
#' Output directory
#' ----------------
odir="$pr/data/gen/multi-origin_reads"
# This should point to a directory containing temporary files
# Ideally, it is a tmpfs file system which stores its contents
# in RAM for better performance (see mount | grep tmpfs for a list)
tmp="/dev/shm/mlell"
mkdir $tmp


#' Change working directory
# mkdir $odir
cd $odir

#' Scripts
#' -------
#'
#' Directory where scripts are.
scd="$pr/mapper-compare"
gscd="$pr/scripts"

#' Index of large genomes
s_fasta_index="$scd/generate-reads/nucl/extract-ref/fasta_record_index"

#' Remove newlines and whitespace in reference genomes (easier indexing)
s_linearize_fasta="$scd/generate-reads/nucl/extract-ref/linearize_fasta"

#' Extraction of fragments out of a reference sequence
s_nucl_uniform="$scd/generate-reads/nucl/extract-ref/uniform.py"

#' Generate quality scores for nucleotide strings
s_quali_const="$scd/generate-reads/quali/gen-constant-score.pl"

#' Compose a FASTQ from its components ID, nucleotide and quality string
s_synth_fastq="$scd/generate-reads/synth-fastq.py"

#' Change the ID, nucleotide sequence or quality string of a FASTQ
s_filter_fastq="$gscd/filter-fastq.py"

#' Count nucleotides
s_count_nucleotides="$gscd/count-nucleotides.pl"

#' Mutate a nucleotide sequence using a table specifying probability parameters
s_multiple_mutate="$scd/induce-errors/multiple_mutate.py"

#' Map reads using BWA
s_map_bwa="$scd/bwa/map-reads-bwa.sh"

#' Data
#' ----
#'
#' Reference sequences
#'
d_ref="$pr/data/in/ref"
d_pubref="/raid6/public/referenceData"

#' This makes an associative array in bash!
declare -A ref

# Ursus spelaeus mitochondium(Mammalia)
ref[uspemito]="$d_ref/NC011112_ingr_mito.fasta"
# Streptomyces coelicolor (Actinomycetes)
ref[scoelicolor]="$d_ref/NC00388.3_scoelicolor.fasta"
# Nostoc sp. (Cyanobacteria)
ref[nostoc]="$d_ref/nostoc_PCC7107_complete.fasta"
# Rhizobium etli (Alphaproteobacteria)
ref[retli]="$d_ref/NC07761.1_retli.fasta"
# Homo sapiens
ref[hsapiens]="$d_pubref/HomoSapiens/homo.fasta"
# Felis catus (cat) 
ref[fcatus]="$d_pubref/FelisCatus/Felis_catus_6.2_all-dna-chromosomes.fasta"

#' Reference genomes which are temporarily unpacked
# Sus scrofa (pig)
ref[sscrofa]="$d_ref/SusScrofa.fasta.gz"

#' Parameter tables for mutation insertion
d_mutpar="$pr/data/gen/snakemake-test/par"

#' Indexed reference of BWA
bwa_ref="$pr/mapper-compare/bwa/Usp_mito/Usp_mito"

#' Get used reference keys:
ref_keys=${!ref[@]}

#' Unpack gzip'ed genomes
#' =======================
for key in "sscrofa"; do
    gunzip -c "${ref[$key]}" > "$tmp/${key}.fasta"
    ref[$key]="$tmp/${key}.fasta"
done


#' Linearize FASTA and generate indices for genomes
#' ================================
for key in $ref_keys; do
    cat << EOF
    $s_linearize_fasta "${ref[$key]}" > $tmp/${key}.fasta.lin
    $s_fasta_index "${ref[$key]}" > "$tmp/${key}.idx"
    EOR
EOF
done | mcall.py --status -t 8 -s EOR > mcall.log

#' Set Paths to FASTAs to temporary location
#' =========================================
for key in $ref_keys; do
    ref[$key]=$tmp/${key}.fasta.lin
done
 


#' Genome sizes
#' ============
for r in ${ref_keys[@]} ;do
    echo -n "$r "
    grep "len" < genome_indices/$r | \
        awk '{i=i+$2} END{print i}'
done | column -t

## uspemito     16780
## sscrofa      2596656069
## nostoc       6329823
## hsapiens     3088286401
## scoelicolor  8667507
## fcatus       2428557402
## retli        4381608


#' Constructing a genome needs about threefold coverage. Read sizes are
#' approximately 40bp. Therefore, (16780/40)*3 ~= 1300 reads are needed for 
#' the *Ursus spelaeus* mitogenome. For the contaminant genomes more reads
#' are generated so that the total count of contaminant reads exceeds 
#' that of U.spelaeus reads multiple-fold.
#' 
#' Sample reads 
#' ============
#' Sample reads from each of the reference sequences
#'
#' Common parameters: read length, std. deviation in read length
readlen=40
readlen_sd=8

declare -A nreads
nreads=( [uspemito]=1300 
         [hsapiens]=2000
         [sscrofa]=2000
         [fcatus]=2000
         [scoelicolor]=2000
         [nostoc]=2000
         [retli]=2000 )

#' Seeds can be choosen arbitrarily. Same seed gives same coordinates
#' of extracted reads.
declare -A seeds
seeds=( [uspemito]=1000
        [hsapiens]=1001
        [sscrofa]=1002
        [fcatus]=1003
        [scoelicolor]=1004
        [nostoc]=1005
        [retli]=1006 )
 
#' Generate the sample reads by randomly choosing sequence fragments
#' of the specified reference genomes
#' These commands generate the files "index.list" and "reads.raw.list"
for k in ${ref_keys};do
    echo $k
    #cat <<EOF
    mkdir $k
    $s_nucl_uniform ${ref[$k]}      --index $tmp/${k}.idx \
                    ${nreads[$k]}   $readlen \
                    $readlen_sd     ${seeds[$k]} > $k/reads.tab
    #EOR
#EOF
done #| mcall.py --status -s EOR -t 12 > mcall.log

#' Remove reads which contain 'N' characters
for k in ${ref_keys}; do
    grep -v "N" $k/reads.tab > $k/tmp && \
    mv $k/tmp $k/reads.tab
    awk '($4 != "")' $k/reads.tab > $k/tmp && \
    mv $k/tmp $k/reads.tab
done

#' Split the output into separate files
#' Columns 1-3 > index.list
#' Column 4    > reads.raw.list
for k in ${ref_keys}; do
    grep -v "^#" $k/reads.tab | \
    awk -v k=$k\
        'BEGIN{OFS="_"} 
         {print $1,$2,$3 > k"/index.list";
          print $4 > k"/reads.raw.list"}'
done


#' Quality scores
#' ==============
#' Generate from the nucleotide strings quality scores: only F, same length
for d in ${ref_keys[@]};do
    $s_quali_const F \
        < $d/reads.raw.list \
        > $d/quali.raw.list
done

#' Add origin to index
#' ===================
#' Example index format now: `mito_1572498_1572538'
for d in ${ref_keys[@]};do
    awk '{print "'$d'_"$0}' $d/index.list > tmp && \
        mv tmp $d/index.list
done

#' Generate FASTQ
#' ==============
for d in ${ref_keys[@]};do
    $s_synth_fastq $d/reads.raw.list $d/quali.raw.list $d/index.list \
        > ${d}.fastq
done

#' Merge FASTQ
#' ===========
m=($(for d in ${ref_keys[@]};do
    echo ${d}.fastq
done))
cat ${m[@]} > all.fastq

#' Insert mutations/deviations
#' ===========================
#' Because of evolution or chemical damage
#' 
#' The parameters derived from the GS136 dataset are used here.
#' They are saved in 'parameter tables'

parfiles=($(ls "$d_mutpar"))
echo ${parfiles[@]}

#' For each of the parameter tables, generate a new FASTQ file 
#' which will carry mutations of the specified strength and distribution
#' @ delimits the parameters of the multiple-mutate script from those
#' of the filter-fastq script
for p in ${parfiles[@]};do
    #p=c_0.01.tab
    # Remove .tab extension
    n=${p%.tab}
    # absolute path to parameter table
    abspath=$d_mutpar/$p
    echo $n
    echo $abspath

    $s_filter_fastq --nucleotide \
        @  $s_multiple_mutate "$abspath" @ \
        < all.fastq \
        > all_${n}.fastq
done

#' Save mutation levels in a tabular file
(echo mut
ls all_*.fastq | \
    sed -r 's/all_c_(.*)\.fastq/\1/g'
) > mut.tab

cat mut.tab 


#' Delete temporary files
#' ======================

rm -rv $tmp

# vim: filetype=sh:tw=80
